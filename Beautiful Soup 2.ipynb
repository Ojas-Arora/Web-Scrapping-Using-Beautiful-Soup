{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8e2627-4196-4e16-a6c9-111580bf7215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicking on this takes you to the documentation of BeautifulSoup\n"
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = BeautifulSoup(html, 'html.parser')\n",
    "page = data.find_all(\"a\")[1]\n",
    "print(page.next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7bcd285-8211-47ba-a6d3-d86f5cd8619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.codingninjas.in/\n",
      "https://www.facebook.com/codingninjas/\n"
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "data = BeautifulSoup(html, 'html.parser')\n",
    "ans = data.find_all('a')\n",
    "for ele in ans:\n",
    "    print(ele.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb7f669-7e02-498b-b43c-1042934ad427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "li\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "data = BeautifulSoup(html, 'html.parser')\n",
    "ans = data.find_all(id = True)\n",
    "for i in ans:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3121143b-aaf0-45d2-8689-0c36d78045ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an unordered list. "
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "data = BeautifulSoup(html, 'html.parser')\n",
    "ans = data.find_all('li')\n",
    "for ele in ans:\n",
    "    print(ele.text, end = \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77108b82-2edc-468b-a1cb-247528be2b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n"
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "data = BeautifulSoup(html, 'html.parser')\n",
    "ans = data.div.attrs\n",
    "for ele in ans:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae2bae8a-7dff-4a24-a350-6c9c96fcc2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "data = BeautifulSoup(html, 'html.parser')\n",
    "li1 = list(data.html.children)\n",
    "li2 = list(data.html.descendants)\n",
    "print(len(li2) - len(li1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f1d250-c6f3-4bba-839a-8b1274b195ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: head.parser. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m## Print the required output in given format\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m---> 13\u001b[0m data \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mbody)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: head.parser. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Learning Beautiful Soup</title></head>\\\n",
    "<body><h1> About Us </h1><div class = \"first_div\"><p>Coding Ninjas Website</p>\\\n",
    "<a href=\"https://www.codingninjas.in/\">Link to Coding Ninjas Website</a>\\\n",
    "<ul><li>This</li><li>is</li><li>an</li><li>unordered</li><li>list.</li></ul>\\\n",
    "</div><p id = \"template_p\">This is a template paragraph tag</p>\\\n",
    "<a href = \"https://www.facebook.com/codingninjas/\">\\\n",
    "This is the link of our Facebook Page</a></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "data = BeautifulSoup(html, 'head.parser')\n",
    "print(data.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa243a5-6866-4349-bae0-98bd8b6b57c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html 51.77 22 \n",
      "Tipping the Velvet http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html 53.74 20 \n",
      "Soumission http://books.toscrape.com/catalogue/soumission_998/index.html 50.1 20 \n",
      "Sharp Objects http://books.toscrape.com/catalogue/sharp-objects_997/index.html 47.82 20 \n",
      "Sapiens: A Brief History of Humankind http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html 54.23 20 \n",
      "The Requiem Red http://books.toscrape.com/catalogue/the-requiem-red_995/index.html 22.65 19 \n",
      "The Dirty Little Secrets of Getting Your Dream Job http://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html 33.34 19 \n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull http://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html 17.93 19 \n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics http://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html 22.6 19 \n",
      "The Black Maria http://books.toscrape.com/catalogue/the-black-maria_991/index.html 52.15 19 \n",
      "Starving Hearts (Triangular Trade Trilogy, #1) http://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html 13.99 19 \n",
      "Shakespeare's Sonnets http://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html 20.66 19 \n",
      "Set Me Free http://books.toscrape.com/catalogue/set-me-free_988/index.html 17.46 19 \n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) http://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html 52.29 19 \n",
      "Rip it Up and Start Again http://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html 35.02 19 \n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991 http://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html 57.25 19 \n",
      "Olio http://books.toscrape.com/catalogue/olio_984/index.html 23.88 19 \n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849 http://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html 37.59 19 \n",
      "Libertarianism for Beginners http://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html 51.33 19 \n",
      "It's Only the Himalayas http://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html 45.17 19 \n",
      "In Her Wake http://books.toscrape.com/catalogue/in-her-wake_980/index.html 12.84 19 \n",
      "How Music Works http://books.toscrape.com/catalogue/how-music-works_979/index.html 37.32 19 \n",
      "Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More http://books.toscrape.com/catalogue/foolproof-preserving-a-guide-to-small-batch-jams-jellies-pickles-condiments-and-more-a-foolproof-guide-to-making-small-batch-jams-jellies-pickles-condiments-and-more_978/index.html 30.52 19 \n",
      "Chase Me (Paris Nights #2) http://books.toscrape.com/catalogue/chase-me-paris-nights-2_977/index.html 25.27 19 \n",
      "Black Dust http://books.toscrape.com/catalogue/black-dust_976/index.html 34.53 19 \n",
      "Birdsong: A Story in Pictures http://books.toscrape.com/catalogue/birdsong-a-story-in-pictures_975/index.html 54.64 19 \n",
      "America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana http://books.toscrape.com/catalogue/americas-cradle-of-quarterbacks-western-pennsylvanias-football-factory-from-johnny-unitas-to-joe-montana_974/index.html 22.5 19 \n",
      "Aladdin and His Wonderful Lamp http://books.toscrape.com/catalogue/aladdin-and-his-wonderful-lamp_973/index.html 53.13 19 \n",
      "Worlds Elsewhere: Journeys Around Shakespeareâs Globe http://books.toscrape.com/catalogue/worlds-elsewhere-journeys-around-shakespeares-globe_972/index.html 40.3 18 \n",
      "Wall and Piece http://books.toscrape.com/catalogue/wall-and-piece_971/index.html 44.18 18 \n",
      "The Four Agreements: A Practical Guide to Personal Freedom http://books.toscrape.com/catalogue/the-four-agreements-a-practical-guide-to-personal-freedom_970/index.html 17.66 18 \n",
      "The Five Love Languages: How to Express Heartfelt Commitment to Your Mate http://books.toscrape.com/catalogue/the-five-love-languages-how-to-express-heartfelt-commitment-to-your-mate_969/index.html 31.05 18 \n",
      "The Elephant Tree http://books.toscrape.com/catalogue/the-elephant-tree_968/index.html 23.82 18 \n",
      "The Bear and the Piano http://books.toscrape.com/catalogue/the-bear-and-the-piano_967/index.html 36.89 18 \n",
      "Sophie's World http://books.toscrape.com/catalogue/sophies-world_966/index.html 15.94 18 \n",
      "Penny Maybe http://books.toscrape.com/catalogue/penny-maybe_965/index.html 33.29 18 \n",
      "Maude (1883-1993):She Grew Up with the country http://books.toscrape.com/catalogue/maude-1883-1993she-grew-up-with-the-country_964/index.html 18.02 18 \n",
      "In a Dark, Dark Wood http://books.toscrape.com/catalogue/in-a-dark-dark-wood_963/index.html 19.63 18 \n",
      "Behind Closed Doors http://books.toscrape.com/catalogue/behind-closed-doors_962/index.html 52.22 18 \n",
      "You can't bury them all: Poems http://books.toscrape.com/catalogue/you-cant-bury-them-all-poems_961/index.html 33.63 17 \n"
     ]
    }
   ],
   "source": [
    "## Print the required output in given format\n",
    "## You are given page links in variable allPages, use this\n",
    "## Column names of your dataframes should be as per given in the variable column_names\n",
    "\n",
    "allPages = ['http://books.toscrape.com/catalogue/page-1.html',\n",
    "            'http://books.toscrape.com/catalogue/page-2.html']\n",
    "\n",
    "column_names = ['Title', 'Link', 'Price', 'Quantity in Stock']\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bsp\n",
    "import pandas as pd\n",
    "\n",
    "books_details = []\n",
    "for url in allPages:\n",
    "    base_url = 'http://books.toscrape.com/catalogue/'\n",
    "    response = requests.get(url)\n",
    "    data = bsp(response.text, 'html.parser')\n",
    "    arr = data.find_all('article', {'class' : 'product_pod'})\n",
    "    for ele in arr:\n",
    "        title = ele.h3.a['title'].strip()\n",
    "        book_url = base_url + ele.h3.a['href'].strip()\n",
    "        #print(book_url)\n",
    "        response = requests.get(book_url)\n",
    "        data = bsp(response.text, 'html.parser')\n",
    "        price = data.find('p', {'class':'price_color'}).string.strip()\n",
    "        quantity = data.find('p', {'class':'instock availability'}).text.strip()\n",
    "        price = float(re.search('[\\d.]+', price).group())\n",
    "        quantity = int(re.search('\\d+', quantity).group())\n",
    "        books_details.append([title, book_url, price, quantity])\n",
    "\n",
    "\n",
    "for ele in books_details:\n",
    "    for i in ele:\n",
    "        print(i, end = \" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f57f78e-b73c-4f17-a6bd-e897a290bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li>\n",
      "<li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li>\n"
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = BeautifulSoup(html, 'html.parser')\n",
    "page = data.find(\"li\", {\"id\" : \"li2\"})\n",
    "temp = list(page.next_siblings)\n",
    "for ele in temp:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90151477-992f-4f49-9cea-72286221945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>Navigate Parse Tree</title></head>\n",
      "<html><head><title>Navigate Parse Tree</title></head><body><h1>This is your Assignment</h1><a href=\"https://www.google.com\">This is a link that will take you to Google</a><ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p><p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li><li id=\"li2\">This is an li tag given to you for scraping</li><li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li><li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li></ul></body></html>\n",
      "<!DOCTYPE html>\n",
      "<html><head><title>Navigate Parse Tree</title></head><body><h1>This is your Assignment</h1><a href=\"https://www.google.com\">This is a link that will take you to Google</a><ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p><p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li><li id=\"li2\">This is an li tag given to you for scraping</li><li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li><li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li></ul></body></html>\n"
     ]
    }
   ],
   "source": [
    "## HTML Code is provided in variable html\n",
    "\n",
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = BeautifulSoup(html, 'html.parser')\n",
    "page = data.find(\"title\")\n",
    "temp = list(page.parents)\n",
    "for ele in temp:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636a4a4-6eae-4dd5-bb2e-13f1a614c535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
